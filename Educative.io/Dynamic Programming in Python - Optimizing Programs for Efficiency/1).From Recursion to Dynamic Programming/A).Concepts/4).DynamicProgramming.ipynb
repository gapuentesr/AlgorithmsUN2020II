{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4).DynamicProgramming.ipynb","provenance":[{"file_id":"1xfrxiZyzQG4suI65Vvzcxh5LhN379HOo","timestamp":1608023530431},{"file_id":"1f0xpdaWzQuxA19Hltb_U8z_4rSky7Ku6","timestamp":1608020362040},{"file_id":"193sJ6DxNovp9lBDUelzqtkOaDBz9av3G","timestamp":1607731471449}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"sa_nT1sTMsRS"},"source":["<h1>(1). Is Plain Recursion Good Enough?</h1>\r\n","<h2>Recursion = Brute Force</h2>"]},{"cell_type":"markdown","metadata":{"id":"l1YZPAN3fSCd"},"source":["We saw some examples of recursion earlier in this chapter. One recurring theme (pun intended) in all those problems was high time complexity. Why was that the case? Because all those problems required a brute force search. We had to search in the whole solution space to look for an answer. For example, in the permutation challenge, we had to find all the possible combinations of characters. In the N queens problem, we had to look at all possible placements of queens until we found an optimal one. So, recursion in most cases is an excellent brute force technique. But as the name also suggests, it is not a very elegant one; thus, we will be learning about techniques that make recursion more efficient.\r\n","\r\n","**Dynamic programming** is the answer."]},{"cell_type":"markdown","metadata":{"id":"USOh_yiffoca"},"source":["<h1>(2). What is Dynamic Programming?</h1>\r\n","\r\n","Chances are you’ve seen the following quote espoused to dynamic programming before:\r\n","\r\n","Those who cannot remember the past are condemned to repeat it.  ~~ George Santayana\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"FZodHUfRr2O3"},"source":["<h1>(2.1). Why do we need to remember the past?</h1>\r\n","\r\n","Let’s do a small exercise and see what it evaluates too.\r\n","\r\n","> x = 2*2*2*2*2*2*2\r\n","\r\n","Now evaluate the following equation.\r\n","\r\n","> x = x*2\r\n","\r\n","You had to count all the 2s in the first equation, which took some time. But you were able to evaluate the second one much quicker because you remembered what x had evaluated to. Our brain works in a way where we tend to memorize things by default and we use these memories to make future decisions. Well, computers do not have this by default. As we saw in the Fibonacci numbers algorithm given in the last lesson, our algorithm was re-evaluating the same things again and again. If we could enable it to memorize older results that would save us the cost of so many re-evaluations. This is the concept of dynamic programming.\r\n","\r\n","For the problem that depends on subproblems that are being repeatedly re-evaluated, we can store results of these subproblems to avoid re-evaluation.\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"h15oPIWetD-u"},"source":["<h1>(3). Why is it called dynamic programming?</h1>\r\n","\r\n","The technique behind dynamic programming is pretty intuitive and straight-forward. If you want to get rid of the re-evaluation in a problem, then simply memorize its results. Why does it have such a fancy name?\r\n","\r\n","The term dynamic programming was coined by Dr. Richard Bellman while he was working at RAND Corporation on multistage decision processes in the mid-1950s. He writes that his superior there was pretty hostile against the mathematical research. So, to hide the mathematical nature of the algorithm he was working on, Dr. Bellman chose a very clever name. He called it dynamic programming; since programming means finding an optimal solution or making an optimal decision. He called it dynamic to highlight the fact that his solution was multistage.\r\n","\r\n","Turns out these two properties are very common in most of the recursive problems. As we observed in the last few lessons, recursion tends to be a repetitive step-by-step process, thus making it a multistage process. Also, since our end goal is to find an optimal solution, dynamic programming fits pretty well given the nature of recursive problems.\r\n","\r\n","In theory, dynamic programming does not have a lot to do with actual memorization techniques but it is the name of solving problems that depend on subproblems. Memorization techniques are merely an addition to dynamic programming, a much-needed one.\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"rYSjeusDtjmc"},"source":["<h1>(4). Approaches of Dynamic Programming</h1>\r\n","\r\n","here are two basic approaches to solve a problem using dynamic programming. These approaches differ from each other in the way they start solving a problem. In the bottom-up approach, we start from the most basic unit (sub-problem) and then build-up to the solution. Whereas, in the top-down approach, we start from the problem and build and use smaller components(sub-problem) as needed.\r\n"]},{"cell_type":"markdown","metadata":{"id":"tX_X55fUtuOh"},"source":["> <h2>Bottom-up approach</h2>\r\n","\r\n","The basic idea of the bottom-up approach is to start by constructing the smallest units first and then use those small units to build bigger and bigger units. Let’s take the example, suppose you are hired by a construction company to construct a building. There are two ways you might go about doing this task. You might want to start off by constructing the smallest unit which would be a room in this case. Then replicating multiple rooms to construct a floor, and then finally stacking multiple floors to make a building."]},{"cell_type":"markdown","metadata":{"id":"29dkFYD-uIyZ"},"source":["> <h2>Top-down approach</h2>\r\n","\r\n","This is what you have been doing so far with recursion. You start off at the top with a bigger problem, make a recursive call to subproblems and that recursion goes down until you reach your base cases. Recursion is essentially the top-down approach. In the top-down dynamic programming approach, you evaluate something as it is needed and then you can store it and reuse it when needed again."]},{"cell_type":"markdown","metadata":{"id":"AQQUdg9fu97m"},"source":["<h1>(5). Where to Use Dynamic Programming</h1>\r\n","\r\n","Do you remember the run time complexity of the Fibonacci algorithm from earlier lessons? We even saw how bad that algorithm performed as we tried to calculate a slightly higher (~50) Fibonacci number. We have modified that algorithm to remember the values it has already evaluated to avoid re-evaluations. Run this code with different values to see how much time the algorithm takes. For comparison, we have reproduced the simple recursion-based solution below as well as in the other cell.\r\n"]},{"cell_type":"markdown","metadata":{"id":"z0sqwZ65veYR"},"source":["> <h2>Dynamic programming solution:</h2>\r\n","\r\n"]},{"cell_type":"code","metadata":{"id":"1sStFVomvkuh"},"source":["import time\r\n","import matplotlib.pyplot as plt\r\n","\r\n","calculated = {}\r\n","\r\n","def fib(n):\r\n","  if n == 0: # base case 1\r\n","    return 0\r\n","  if n == 1: # base case 2\r\n","    return 1\r\n","  elif n in calculated:\r\n","    return calculated[n]\r\n","  else: # recursive step\r\n","    calculated[n] = fib(n-1) + fib(n-2)\r\n","    return calculated[n]\r\n","\r\n","showNumbers = True\r\n","numbers = 20"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1uOPtF0nwMV_"},"source":["> <h2>Simple recursion solution:</h2>\r\n","\r\n"]},{"cell_type":"code","metadata":{"id":"u8WzxyP4wXyF"},"source":["import time\r\n","import matplotlib.pyplot as plt\r\n","\r\n","def fib(n):\r\n","  if n <= 0: # base case 1\r\n","    return 0\r\n","  if n <= 1: # base case 2\r\n","    return 1\r\n","  else: # recursive step\r\n","    return fib(n-1) + fib(n-2)\r\n","\r\n","numbers = 20"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zk5Yrr85wqs4"},"source":["<h1>(6). Dynamic programming, the ‘selective’ magic wand</h1>\r\n","\r\n","As amazing as dynamic programming is, you cannot use it on every kind of problem. There are a number of problems that entail an exponential complexity, but their complexity cannot be reduced even after using dynamic programming. In fact, a problem needs to meet very strict prerequisites before it can be solved using dynamic programming. These prerequisites are **optimal substructure** and **overlapping subproblems**.\r\n"]},{"cell_type":"markdown","metadata":{"id":"ogN8hX6kw6-M"},"source":["> <h2>Optimal substructure</h2>\r\n","\r\n","This property means that an optimal solution to a problem can be built using the optimal solutions to that problem’s subproblems. Essentially, we should be able to specify the problem in terms of its subproblems in such a way that if we know the optimal answer to the subproblem, the evaluation of the problem can simply use that answer. This might seem straightforward, but it is a little tricky. Let’s look at two examples to see what we mean."]},{"cell_type":"markdown","metadata":{"id":"yERgw8KSxP7C"},"source":["> <h2>Overlapping subproblems</h2>\r\n","\r\n","We now know dynamic programming is all about avoiding recomputations. Therefore, dynamic programming will only be beneficial to those problems that have repeating subproblems. For example, we have already seen how the Fibonacci numbers algorithm has so many overlapping subproblems.\r\n","\r\n","In summary, a problem only benefits from dynamic programming if it has a solution that builds from the solution of subproblems and if these subproblems are being evaluated over and over again.."]}]}